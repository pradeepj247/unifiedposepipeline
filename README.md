# Unified Pose Estimation Pipeline

A comprehensive pose estimation framework combining **ViTPose+HybrIK** and **RTMLib** into a single, unified pipeline.

## ğŸ¯ Overview

This repository unifies two powerful pose estimation approaches:

1. **ViTPose + HybrIK Pipeline**: Vision Transformer-based pose estimation with SMPL body model support
2. **RTMLib Pipeline**: Lightweight real-time pose estimation using RTMPose models

### Key Features

- âœ… **Unified Installation**: Single requirements.txt for both pipelines
- âœ… **Shared YOLO Detection**: Common object detection framework
- âœ… **Flexible Model Selection**: Switch between ViTPose and RTMLib easily
- âœ… **Multiple Output Formats**: 2D keypoints, 3D poses, SMPL parameters
- âœ… **Production Ready**: Optimized for both research and deployment

## ğŸ“¦ Installation

### Prerequisites

- Python 3.8+
- CUDA 11.8+ (optional, for GPU acceleration)
- 10GB+ disk space (for models)

### ğŸš€ Quick Start (Automated Setup)

**Recommended**: Use the automated setup script that handles everything:

```bash
# Clone the repository
git clone <your-repo-url>
cd newrepo

# Run the complete setup (installs everything + downloads models)
python setup_environment.py

# Verify the installation
python verify_environment.py
```

The `setup_environment.py` script will:
- âœ… Check Python version and environment
- âœ… Install all dependencies (PyTorch, OpenCV, YOLO, etc.)
- âœ… Verify library structure
- âœ… Download essential YOLO models
- âœ… Provide detailed progress and error messages
- âœ… Run verification tests

### ğŸ“ Manual Installation (Alternative)

If you prefer manual control:

```bash
# 1. Install core dependencies
pip install -r requirements.txt

# 2. Install PyTorch with CUDA (for GPU)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# 3. Download models
python download_models.py

# 4. Verify installation
python verify_environment.py
```

### GPU Setup Notes

- The automated setup detects GPU and installs appropriate drivers
- For CPU-only: Setup script automatically configures for CPU
- For custom CUDA versions: Edit `setup_environment.py` Step 2

## ğŸš€ Quick Usage

### Using ViTPose Pipeline

```python
from lib.vitpose_wrapper import ViTPosePipeline

# Initialize pipeline
pipeline = ViTPosePipeline()

# Process image
results = pipeline.process_image('path/to/image.jpg')
```

### Using RTMLib Pipeline

```python
from lib.rtmlib_wrapper import RTMLibPipeline

# Initialize pipeline
pipeline = RTMLibPipeline()

# Process image
results = pipeline.process_image('path/to/image.jpg')
```

### Unified Interface

```python
from lib.unified_pose import UnifiedPoseEstimator

# Use either 'vitpose' or 'rtmlib'
estimator = UnifiedPoseEstimator(backend='vitpose')

# Process with consistent API
results = estimator.estimate('path/to/image.jpg')
```

## ğŸ“ Project Structure

```
newrepo/
â”œâ”€â”€ lib/                      # Core library code
â”‚   â”œâ”€â”€ vitpose/             # ViTPose+HybrIK implementation
â”‚   â”œâ”€â”€ rtmlib/              # RTMLib implementation
â”‚   â”œâ”€â”€ vitpose_wrapper.py   # ViTPose API wrapper
â”‚   â”œâ”€â”€ rtmlib_wrapper.py    # RTMLib API wrapper
â”‚   â””â”€â”€ unified_pose.py      # Unified interface
â”œâ”€â”€ demos/                   # Example scripts
â”‚   â”œâ”€â”€ demo_vitpose.py
â”‚   â”œâ”€â”€ demo_rtmlib.py
â”‚   â””â”€â”€ demo_comparison.py
â”œâ”€â”€ notebooks/               # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_setup.ipynb
â”‚   â”œâ”€â”€ 02_vitpose_demo.ipynb
â”‚   â”œâ”€â”€ 03_rtmlib_demo.ipynb
â”‚   â””â”€â”€ 04_comparison.ipynb
â”œâ”€â”€ models/                  # Pre-trained models (downloaded)
â”œâ”€â”€ configs/                 # Configuration files
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ setup.py                # Package setup
â””â”€â”€ README.md               # This file
```

## ğŸ”§ Configuration

Configuration files are stored in `configs/`:

- `vitpose_config.yaml`: ViTPose settings
- `rtmlib_config.yaml`: RTMLib settings
- `unified_config.yaml`: Unified pipeline settings

## ğŸ“Š Model Zoo

### ViTPose Models
- ViTPose-Small (256x192)
- ViTPose-Base (256x192)
- ViTPose-Large (256x192)
- ViTPose-Huge (256x192)

### RTMLib Models
- RTMPose-t (tiny)
- RTMPose-s (small)
- RTMPose-m (medium)
- RTMPose-l (large)

## ğŸ“ Citation

If you use this unified pipeline in your research, please cite the original works:

### ViTPose
```bibtex
@inproceedings{xu2022vitpose,
  title={ViTPose: Simple Vision Transformer Baselines for Human Pose Estimation},
  author={Xu, Yufei and Zhang, Jing and Zhang, Qiming and Tao, Dacheng},
  booktitle={NeurIPS},
  year={2022}
}
```

### RTMLib
```bibtex
@misc{rtmlib2023,
  title={RTMLib: Real-time Multi-person Pose Estimation Library},
  author={Tau-J and contributors},
  year={2023},
  howpublished={\url{https://github.com/Tau-J/rtmlib}}
}
```

## ğŸ“ License

This unified repository maintains the original licenses:
- ViTPose components: See original license
- RTMLib components: See original license

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“§ Contact

For questions and issues, please open an issue on GitHub.

---

**Note**: This is a unified implementation combining easy-pose-pipeline and rtmlib. All essential components have been consolidated for ease of use and maintenance.
