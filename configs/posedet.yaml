# 2D Pose Detection Configuration
# This config is for standalone 2D pose estimation using pre-computed detections

# Pose estimation model to use
pose_estimation_model: rtmpose  # Options: rtmpose, vitpose, rtmpose_h26, wholebody

# Model configurations
rtmpose:
  pose_model_path: unifiedposepipeline/models/rtmlib/rtmpose-l-coco-384x288.onnx
  pose_input_size: [288, 384]
  backend: onnxruntime
  device: cuda

rtmpose_h26:
  pose_model_path: unifiedposepipeline/models/rtmlib/rtmpose-l-halpe26-384x288.onnx
  pose_input_size: [288, 384]
  backend: onnxruntime
  device: cuda

vitpose:
  model_path: unifiedposepipeline/models/vitpose/vitpose-b.pth
  model_name: b
  dataset: coco
  device: cuda

wholebody:
  pose_model_path: unifiedposepipeline/models/wb3d/rtmw3d-l.onnx
  pose_input_size: [288, 384]
  backend: onnxruntime
  device: cuda

# Input video files (auto-fallback)
# Primary: canonical_video.mp4 from Stage 0 (normalized/validated)
# Fallback: Original video if Stage 0 was skipped
input_video_primary: demo_data/outputs/kohli_nets/canonical_video.mp4
input_video_fallback: demo_data/videos/kohli_nets.mp4

# Detections file from Stage 5 (selected_person.npz)
detections_file: demo_data/outputs/kohli_nets/selected_person.npz

# Maximum frames to process (null or 0 to process all frames)
# For full video: set to null or 0
# For testing: set to 100-200
max_frames: 600  # Quick test (600 frames = ~24 seconds @ 25fps)

# Output directory (filename will be auto-generated based on model type)
output_dir: demo_data/outputs
