# UDP Video Configuration - 3-Stage Pipeline
# Stage 1: Detection → NPZ | Stage 2: Pose → NPZ | Stage 3: Visualization → Video

detection:
  model_path: yolov8s.pt
  confidence_threshold: 0.5

pose_estimation:
  method: rtmpose  # Options: rtmpose, rtmpose_halpe26, vitpose, wb3d
  
  rtmpose:
    pose_model_path: models/rtmlib/rtmpose-l-coco-384x288.onnx
    pose_input_size: [288, 384]
    backend: onnxruntime
    device: cuda
  
  rtmpose_halpe26:
    pose_model_path: models/rtmlib/rtmpose-l-halpe26-384x288.onnx
    pose_input_size: [288, 384]
    backend: onnxruntime
    device: cuda
  
  vitpose:
    model_path: models/vitpose/vitpose-b.pth
    model_name: b
    dataset: coco
    device: cuda
  
  wb3d:
    pose_model_path: models/wb3d/rtmw3d-l.onnx
    pose_input_size: [288, 384]
    backend: onnxruntime
    device: cuda

video:
  input_path: demo_data/videos/dance.mp4
  max_frames: 360  # Set to null to process all frames

output:
  stage1_detections: demo_data/outputs/detections.npz
  stage2_keypoints: demo_data/outputs/keypoints.npz
  video_output: demo_data/outputs/result.mp4
  plot: true  # Set to false to skip visualization stage
