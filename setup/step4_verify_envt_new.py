#!/usr/bin/env python3
"""
Step 4: Verify Environment (YAML-driven)

This script performs comprehensive verification of the installation by reading
configuration from the YAML files used in steps 1-3.

Verification includes:
- Package imports and versions (from libraries.yaml)
- CUDA/GPU availability
- Model files (from models.yaml)
- Demo data (from demodata.yaml)

Usage:
    python step4_verify_envt_new.py
"""

import os
import sys
import yaml
import importlib
import importlib.metadata
from pathlib import Path


def is_colab_environment():
    """Check if running in Google Colab"""
    try:
        import google.colab
        return True
    except ImportError:
        return False


def print_header(text, emoji="üõ†Ô∏è"):
    """Print a formatted section header"""
    print("\n  " + "‚îÄ" * 66)
    print(f"  {emoji} {text}")
    print("  " + "‚îÄ" * 66 + "\n")


def print_step(step_num, text):
    """Print a step header"""
    print(f"\n  üìã Step {step_num}: {text}")
    print("  " + "‚îÄ" * 60)


def print_error(text):
    """Print error message in red"""
    print(f"\033[91m  ‚úó {text}\033[0m")


def print_success(text):
    """Print success message"""
    print(f"  ‚úÖ {text}")


def print_warning(text):
    """Print warning message"""
    print(f"  ‚ö†Ô∏è  {text}")


def print_info(text):
    """Print info message"""
    print(f"  {text}")


# Configuration
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
LIBRARIES_YAML = os.path.join(SCRIPT_DIR, "libraries.yaml")
MODELS_YAML = os.path.join(SCRIPT_DIR, "models.yaml")
DEMODATA_YAML = os.path.join(SCRIPT_DIR, "demodata.yaml")

REPO_ROOT = "/content/unifiedposepipeline" if is_colab_environment() else os.getcwd()


def load_yaml_config(yaml_file):
    """Load configuration from YAML file"""
    if not os.path.exists(yaml_file):
        print_error(f"Config file not found: {yaml_file}")
        return None
    
    with open(yaml_file, 'r') as f:
        return yaml.safe_load(f)


def get_package_version(package_name):
    """Get installed version of a package"""
    try:
        # Try importlib.metadata first (Python 3.8+)
        version = importlib.metadata.version(package_name)
        return version
    except importlib.metadata.PackageNotFoundError:
        # Try package.__version__ as fallback
        try:
            module = importlib.import_module(package_name)
            if hasattr(module, '__version__'):
                return module.__version__
            return "unknown"
        except:
            return "unknown"


def get_import_name(package_name):
    """
    Map package names to their import names.
    Some packages have different pip names vs import names.
    """
    mapping = {
        'opencv-python': 'cv2',
        'opencv-contrib-python': 'cv2',
        'pillow': 'PIL',
        'pyyaml': 'yaml',
        'scikit-learn': 'sklearn',
        'scikit-image': 'skimage',
        'onnxruntime-gpu': 'onnxruntime',  # GPU variant imports as onnxruntime
    }
    return mapping.get(package_name, package_name)


def check_package_import(package_name):
    """Check if a package can be imported"""
    import_name = get_import_name(package_name)
    
    try:
        # Special handling for ultralytics (suppress settings output)
        if package_name == 'ultralytics':
            import warnings
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                importlib.import_module(import_name)
        else:
            importlib.import_module(import_name)
        return True
    except ImportError:
        return False


def verify_python_packages():
    """Verify all packages from libraries.yaml"""
    print_step("4.1", "Package Verification")
    
    config = load_yaml_config(LIBRARIES_YAML)
    if not config:
        return False
    
    all_packages = []
    success_count = 0
    failed_packages = []
    
    # Extract all packages from library groups
    for group in config.get('library_groups', []):
        for pkg in group.get('packages', []):
            package_name = pkg.get('package_name')
            
            # Handle GPU variants
            gpu_variant = pkg.get('gpu_variant')
            if gpu_variant:
                # Check if GPU is available to determine which package to verify
                try:
                    import torch
                    if torch.cuda.is_available():
                        package_name = gpu_variant
                except:
                    pass
            
            all_packages.append(package_name)
    
    # Verify each package
    print()
    for package_name in all_packages:
        can_import = check_package_import(package_name)
        
        if can_import:
            version = get_package_version(package_name)
            import_name = get_import_name(package_name)
            
            # Show import name if different from package name
            if import_name != package_name:
                print(f"  üì¶ {package_name} ‚Üí {import_name} ({version}) ‚úì")
            else:
                print(f"  üì¶ {package_name} ({version}) ‚úì")
            
            success_count += 1
        else:
            print_error(f"{package_name} ‚úó FAILED TO IMPORT")
            failed_packages.append(package_name)
    
    print(f"\n  üìä {success_count}/{len(all_packages)} packages verified")
    
    if failed_packages:
        print_warning(f"Missing packages: {', '.join(failed_packages)}")
        return False
    
    return True


def verify_cuda_gpu():
    """Verify CUDA and GPU availability"""
    print_step("4.2", "Environment Verification (CUDA/GPU)")
    
    try:
        import torch
        
        print(f"\n  üîπ PyTorch version: {torch.__version__}")
        print(f"  üîπ CUDA available: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            print(f"  üîπ CUDA version: {torch.version.cuda}")
            print(f"  üîπ GPU count: {torch.cuda.device_count()}")
            print(f"  üîπ GPU device: {torch.cuda.get_device_name(0)}")
            gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1e9
            print(f"  üîπ GPU memory: {gpu_memory_gb:.1f} GB")
            print_success("CUDA environment verified")
            return True
        else:
            print_warning("CUDA not available - will use CPU (slower)")
            return False
            
    except Exception as e:
        print_error(f"Failed to check CUDA: {e}")
        return False


def verify_model_files():
    """Verify all model files from models.yaml"""
    print_step("4.3", "Model Files Verification")
    
    config = load_yaml_config(MODELS_YAML)
    if not config:
        return False
    
    models = config.get('models', [])
    destination_folder = config.get('destination_folder', '/content/models/')
    
    success_count = 0
    missing_models = []
    
    print()
    for model in models:
        model_name = model.get('name')
        filename = model.get('filename')
        subfolder = model.get('subfolder', '')
        
        # Build full path
        model_path = os.path.join(destination_folder, subfolder, filename)
        
        if os.path.isfile(model_path):
            # Get file size
            size_mb = os.path.getsize(model_path) / (1024 * 1024)
            print(f"  üì¶ {model_name} ({size_mb:.1f} MB) ‚úì")
            success_count += 1
        else:
            print_error(f"{model_name} ‚úó NOT FOUND")
            print(f"      Expected: {model_path}")
            missing_models.append(model_name)
    
    print(f"\n  üìä {success_count}/{len(models)} model files verified")
    
    if missing_models:
        print_warning(f"Missing models: {', '.join(missing_models)}")
        return False
    
    return True


def verify_demo_data():
    """Verify demo data from demodata.yaml"""
    print_step("4.4", "Demo Data Verification")
    
    config = load_yaml_config(DEMODATA_YAML)
    if not config:
        return False
    
    demo_groups = config.get('demo_groups', [])
    destination_folder = config.get('global_settings', {}).get('destination_folder', '/content/unifiedposepipeline/demo_data')
    
    success_count = 0
    missing_data = []
    
    print()
    for group in demo_groups:
        group_name = group.get('name')
        subfolder = group.get('subfolder')
        
        # Build directory path
        data_path = os.path.join(destination_folder, subfolder)
        
        if os.path.isdir(data_path):
            # Count files in directory
            files = [f for f in os.listdir(data_path) if os.path.isfile(os.path.join(data_path, f))]
            file_count = len(files)
            
            if file_count > 0:
                print(f"  üìÅ {group_name}: {file_count} file(s) ‚úì")
                print(f"      Location: {data_path}")
                success_count += 1
            else:
                print_warning(f"{group_name}: directory exists but empty")
                print(f"      Location: {data_path}")
                missing_data.append(group_name)
        else:
            print_error(f"{group_name} ‚úó DIRECTORY NOT FOUND")
            print(f"      Expected: {data_path}")
            missing_data.append(group_name)
    
    print(f"\n  üìä {success_count}/{len(demo_groups)} demo data groups verified")
    
    if missing_data:
        print_warning(f"Missing demo data: {', '.join(missing_data)}")
        return False
    
    return True


def verify_tensorrt_engine():
    """Verify TensorRT engine can load and run inference"""
    print_step("4.5", "TensorRT Engine Verification")
    
    # Find yolov8n.engine (smallest/fastest to test)
    config = load_yaml_config(MODELS_YAML)
    if not config:
        print_warning("Cannot load models config - skipping TensorRT check")
        return None  # Not critical, return None (not False)
    
    destination_folder = config.get('destination_folder', '/content/models/')
    engine_path = os.path.join(destination_folder, 'yolo', 'yolov8n.engine')
    
    print()
    if not os.path.exists(engine_path):
        print_warning("TensorRT engine not found (optional optimization)")
        print(f"      Expected: {engine_path}")
        print(f"      üí° Run: python det_track/debug/export_yolo_tensorrt.py")
        print(f"      Or: Restore from backup (step2_fetch_models.py)")
        return None  # Not critical, return None
    
    print(f"  üì¶ Found: yolov8n.engine")
    print(f"      Location: {engine_path}")
    
    try:
        # Suppress ultralytics verbose output
        import warnings
        import os as os_module
        os_module.environ['YOLO_VERBOSE'] = 'False'
        
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            
            # Import after setting env
            from ultralytics import YOLO
            import numpy as np
            
            print(f"  ‚è≥ Loading engine...")
            model = YOLO(engine_path, verbose=False)
            
            print(f"  ‚è≥ Running test inference...")
            # Create dummy 640x640 RGB image (random data is fine)
            dummy_image = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)
            
            # Run inference (suppress output)
            result = model(dummy_image, verbose=False)
            
            print_success("TensorRT engine loaded and executed successfully!")
            print(f"      ‚úì CUDA kernels functional")
            print(f"      ‚úì Memory transfers working")
            print(f"      ‚úì Inference pipeline validated")
            
            # Get environment info
            try:
                import torch
                print(f"\n  üìä Current Environment:")
                print(f"      PyTorch: {torch.__version__}")
                print(f"      CUDA: {torch.version.cuda}")
                print(f"      GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}")
            except:
                pass
            
            return True
            
    except Exception as e:
        print_error(f"TensorRT engine failed to load/run")
        print(f"      Error: {str(e)}")
        print(f"\n  ‚ö†Ô∏è  INCOMPATIBLE ENGINE - Environment may have changed!")
        print(f"      This happens when CUDA/GPU versions change between sessions")
        print(f"\n  üîß SOLUTION: Re-export engines for current environment")
        print(f"      Run: python det_track/debug/check_tensorrt_compatibility.py \\")
        print(f"           --models-dir {os.path.join(destination_folder, 'yolo')} \\")
        print(f"           --auto-reexport")
        print(f"\n  üìö See: TENSORRT_COMPATIBILITY.md for details")
        return False


def main():
    """Main execution function"""
    print_header("STEP 4: Verify Environment", emoji="üîç")
    
    print("  This script will verify your installation by reading configurations")
    print("  from the YAML files used in steps 1-3.\n")
    print(f"  üìÇ Repository root: {REPO_ROOT}")
    print(f"  üìÇ Libraries config: {LIBRARIES_YAML}")
    print(f"  üìÇ Models config: {MODELS_YAML}")
    print(f"  üìÇ Demo data config: {DEMODATA_YAML}")
    
    results = {}
    
    try:
        # Run all verification steps
        results["packages"] = verify_python_packages()
        results["cuda"] = verify_cuda_gpu()
        results["models"] = verify_model_files()
        results["demo_data"] = verify_demo_data()
        # DISABLED: TensorRT verification (using PyTorch models for Colab compatibility)
        # results["tensorrt_engine"] = verify_tensorrt_engine()
        
        # Summary
        print("\n" + "  " + "=" * 66)
        print("  üìã VERIFICATION SUMMARY")
        print("  " + "=" * 66 + "\n")
        
        # Count passes (None = optional, don't count as fail)
        critical_results = {k: v for k, v in results.items() if v is not None}
        passed = sum(1 for v in critical_results.values() if v)
        total = len(critical_results)
        
        for check, status in results.items():
            if status is None:
                status_str = "‚äò SKIP (optional)"
                status_emoji = "‚ö†Ô∏è "
            elif status:
                status_str = "‚úì PASS"
                status_emoji = "‚úÖ"
            else:
                status_str = "‚úó FAIL"
                status_emoji = "‚ùå"
            print(f"  {status_emoji} {check.upper():20s} {status_str}")
        
        print(f"\n  üìä Overall: {passed}/{total} critical checks passed")
        
        if passed == total:
            print_success("Environment verification complete! All checks passed.")
            print("\n  You can now use the pipeline:")
            print("    python udp_video.py --config configs/udp_video.yaml")
            print("    python udp_image.py --config configs/udp_image.yaml")
        else:
            print_warning("Some checks failed. Please review the output above.")
            print("\n  üí° You may need to:")
            print("    - Re-run step1_install_libs.py for missing packages")
            print("    - Re-run step2_fetch_models.py for missing models")
            print("    - Re-run step3_fetch_demodata.py for missing demo data")
        
        print()
        
    except KeyboardInterrupt:
        print("\n\n  ‚äò Verification interrupted by user")
        sys.exit(1)
    except Exception as e:
        print_error(f"Unexpected error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
