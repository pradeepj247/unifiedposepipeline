# Detection & Tracking Pipeline Configuration
# Multi-stage pipeline for person detection, tracking, and identity resolution

# ============================================================================
# Global Path Variables (Single Source of Truth)
# ============================================================================
global:
  # Repository root - change this for different environments
  repo_root: /content/unifiedposepipeline  # Colab
  # repo_root: D:/trials/unifiedpipeline/newrepo  # Windows (uncomment for local)
  
  # Derived paths (use ${variable} syntax)
  models_dir: ${repo_root}/models
  demo_data_dir: ${repo_root}/demo_data
  outputs_dir: ${demo_data_dir}/outputs
  
  # Video input settings - change video_file to process different videos
  video_dir: ${demo_data_dir}/videos/
  video_file: kohli_nets.mp4

# ============================================================================
# Pipeline Stage Control - SINGLE SOURCE OF TRUTH
# ============================================================================
# NOTE: These settings ALONE control which stages execute.
# Individual stage configs (e.g., stage6_create_output_video: enabled:) are
# IGNORED by run_pipeline.py and should NOT be used to enable/disable stages.
# Use ONLY the settings below to control pipeline execution.
# ============================================================================
pipeline:
  # Stage execution control - the ONLY place to enable/disable stages
  stages:
    stage1_detect: true                    # YOLO detection
    stage2_track: true                     # ByteTrack offline tracking
    stage3_analyze: true                   # Tracklet statistics & candidate analysis
    stage4a_reid_recovery: true            # Load crops cache (lightweight)
    stage4b_group_canonical: true          # Group tracklets into canonical persons
    stage5_rank: true                      # Rank persons by appearance time
    stage5b_visualize_grouping: false      # Optional: Show grouping tables (debug)
    stage6_create_output_video: true       # Create video visualization of top 10 persons
    stage6b_create_selection_grid: false   # Create HTML selection report (alternative to video)
  
  # Global settings inherited by all stages (can be overridden per-stage if needed)
  advanced:
    verbose: false                         # Debug output for all stages (set true to see detailed logs)


# ============================================================================
# Stage 1: Detection
# ============================================================================
stage1_detect:
  detector:
    type: yolo
    model_path: ${models_dir}/yolo/yolov8s.pt  # Use .engine for TensorRT (requires tensorrt package)
    confidence: 0.3
    device: cuda
    detect_only_humans: true
  
  detection_limit:
    method: hybrid  # Options: top_n, confidence, hybrid
    max_count: 15   # Maximum detections per frame
    min_confidence: 0.3  # Minimum confidence threshold
  
  processing:
    batch_size: 1
  
  input:
    max_frames: 0  # 0 = all frames
  
  output:
    detections_file: ${outputs_dir}/${current_video}/detections_raw.npz
    crops_cache_file: ${outputs_dir}/${current_video}/crops_cache.pkl

# ============================================================================
# Stage 2: Tracking (ByteTrack Offline)
# ============================================================================
stage2_track:
  tracker:
    type: bytetrack  # Only bytetrack/ocsort supported for offline mode
  
  params:
    track_thresh: 0.15     # Confidence threshold for tracking (lowered for better recall)
    track_buffer: 30       # Buffer size for lost tracks (frames)
    match_thresh: 0.8      # IOU threshold for matching
    min_hits: 1            # Minimum consecutive detections to create track (1=immediate)
  
  input:
    detections_file: ${outputs_dir}/${current_video}/detections_raw.npz
  
  output:
    tracklets_file: ${outputs_dir}/${current_video}/tracklets_raw.npz

# ============================================================================
# Stage 3: Tracklet Analysis
# ============================================================================
stage3_analyze:
  analysis:
    compute_statistics: true  # Temporal, spatial, motion stats
    identify_candidates: true # Find suspicious tracklet pairs for ReID
  
  candidate_criteria:
    max_temporal_gap: 50       # Frames between tracklet end/start
    max_spatial_distance: 300  # Pixels between last/first bbox centers
    area_ratio_range: [0.6, 1.4]  # Min/max area ratio for size consistency
  
  input:
    tracklets_file: ${outputs_dir}/${current_video}/tracklets_raw.npz
  
  output:
    tracklet_stats_file: ${outputs_dir}/${current_video}/tracklet_stats.npz
    candidates_file: ${outputs_dir}/${current_video}/reid_candidates.json

# ============================================================================
# Stage 4a: Load Crops Cache (Lightweight - No ReID Recovery)
# ============================================================================
# NOTE: This is the lightweight version that loads pre-cached crops from Stage 1
# It does NOT perform ReID-based tracklet recovery
# For full ReID-based recovery, use the old stage4a_reid_recovery_onnx.py
stage4a_reid_recovery:
  input:
    crops_cache_file: ${outputs_dir}/${current_video}/crops_cache.pkl
  
  output:
    # No outputs - crops cache is loaded and passed to Stage 7

# ============================================================================
# Stage 4b: Canonical Person Grouping
# ============================================================================
# To disable this stage, set pipeline.stages.stage4b_group_canonical to false
stage4b_group_canonical:
  grouping:
    method: heuristic  # Options: heuristic, clustering, hybrid
    
    # Heuristic rules
    heuristic_criteria:
      max_temporal_gap: 30
      max_spatial_distance: 200
      area_ratio_range: [0.7, 1.3]
      max_velocity_diff: 50  # pixels/frame
  
  input:
    # Auto-resolved based on stage4a.enabled
    recovered_tracklets_file: ${outputs_dir}/${current_video}/tracklets_recovered.npz
    tracklets_raw_file: ${outputs_dir}/${current_video}/tracklets_raw.npz
    tracklet_stats_file: ${outputs_dir}/${current_video}/tracklet_stats.npz
  
  output:
    canonical_persons_file: ${outputs_dir}/${current_video}/canonical_persons.npz
    grouping_log_file: ${outputs_dir}/${current_video}/grouping_log.json

# ============================================================================
# Stage 5: Ranking and Primary Person Selection
# ============================================================================
stage5_rank:
  ranking:
    method: auto  # Options: auto (manual selection not yet implemented)
    
    # Auto-ranking weights
    weights:
      duration: 0.4       # Longest presence in video
      coverage: 0.3       # Percentage of frames covered
      center: 0.2         # Proximity to frame center
      smoothness: 0.1     # Motion stability (less jitter)
  
  input:
    canonical_persons_file: ${outputs_dir}/${current_video}/canonical_persons.npz
  
  output:
    primary_person_file: ${outputs_dir}/${current_video}/primary_person.npz
    ranking_report_file: ${outputs_dir}/${current_video}/ranking_report.json

# ============================================================================
# Stage 6: Create Output Video - Visualization of Top 10 Persons
# ============================================================================
# To disable this stage, set pipeline.stages.stage6_create_output_video to false
stage6_create_output_video:
  
  visualization:
    min_duration_seconds: 5    # Minimum appearance time to be included
    max_persons_shown: 10      # Show top 10 persons (or all if <10 qualify)
  
  input:
    canonical_persons_file: ${outputs_dir}/${current_video}/canonical_persons.npz
  
  output:
    video_file: ${outputs_dir}/${current_video}/top_persons_visualization.mp4

# ============================================================================
# Stage 6b: Create Selection HTML Report (Alternative to Stage 6 Video)
# ============================================================================
# To disable this stage, set pipeline.stages.stage6b_create_selection_grid to false
stage6b_create_selection_grid:
  
  filters:
    min_duration_seconds: 5    # Minimum appearance time to be included
    max_persons_shown: 10      # Show top 10 persons (or all if <10 qualify)
  
  full_frame_grid:
    target_frame_count: 10     # Target number of frames to show (adaptive if fewer persons)
    cell_size: [384, 216]      # Cell dimensions (width x height)
  
  cropped_grid:
    bbox_padding_percent: 10   # Padding around person bbox (uniform)
    max_cell_size: [384, 600]  # Maximum cell dimensions
  
  output:
    fullframe_grid: ${outputs_dir}/${current_video}/top10_persons_fullframe_grid.png
    cropped_grid: ${outputs_dir}/${current_video}/top10_persons_cropped_grid.png
    selection_info: ${outputs_dir}/${current_video}/selection_grid_info.json
