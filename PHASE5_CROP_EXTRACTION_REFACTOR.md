# Phase 5: Architecture Refactoring - Crop Extraction Move

## ğŸ¯ Objective
Eliminate redundant video scanning in Stage 4 by moving crop extraction to Stage 3c and introducing quality-aware crop selection for better clustering.

## âœ… Completed Tasks

### 1. Created `crop_utils.py` - Shared Crop Extraction Module
**Location**: `det_track/crop_utils.py`

**Key Functions**:
```python
extract_crops_with_quality()      # Extract crops with quality metrics
save_final_crops()                # Save to final_crops.pkl
load_final_crops()                # Load with error handling
compute_crop_quality_metrics()    # Calculate quality per crop
compute_crop_quality_rank()       # Rank crops by quality
```

**Quality Metrics Computed**:
- `confidence`: Detection confidence (0-1) from YOLO
- `width`, `height`: Crop dimensions in pixels
- `area`: Total pixels (width Ã— height)
- `aspect_ratio`: width/height ratio
- `visibility_score`: 0-1 based on:
  - Aspect ratio quality (penalizes very wide/tall crops)
  - Size appropriateness (avoid too small or too large)
  - Center positioning (prefer centered crops)
- `quality_rank`: 1-50 (1=best, 50=worst)

### 2. Modified `stage3c_rank_persons.py` - Added Crop Extraction
**Changes**:
- Imports `crop_utils` module
- After person ranking completes, extracts crops from video
- Computes quality metrics for each crop
- Saves to `final_crops.pkl` in output directory
- Updates timing sidecar with crop extraction time

**Output**: `final_crops.pkl` containing:
```python
{
    'person_ids': [3, 4, 20, 29, 37, 40, 65, 66],
    'crops': {
        person_id: np.array(...),  # (50, H, W, 3) images
        # ...
    },
    'metadata': {
        person_id: [
            {
                'confidence': 0.95,
                'width': 100,
                'height': 128,
                'area': 12800,
                'aspect_ratio': 0.78,
                'visibility_score': 0.92,
                'quality_rank': 3,
                'quality_score': 0.81,
                'frame_number': 45
            },
            # ... 49 more crops per person
        ]
    },
    'global_metadata': {
        'timestamp': '2026-01-15T...',
        'video_source': '/content/.../dance.mp4',
        'total_persons': 8,
        'total_crops': 400,
        'crops_per_person': 50,
        'format_version': '1.0'
    }
}
```

**Timeline Impact**: 
- Adds ~11 seconds to Stage 3c runtime
- One-time extraction (Stage 4 will be much faster)

### 3. Refactored `stage4_generate_html.py` - Four Sub-Stages
**Architecture**: Split into 4a-4d (load, cluster, WebP, HTML)

#### Stage 4a: Load Crops
```python
# Load final_crops.pkl from Stage 3c
crops_data = load_final_crops(final_crops_path)

# Convert to person_buckets format
person_buckets = {person_id: [crop1, crop2, ...]}
person_metadata = {person_id: [{quality metrics}, ...]}
```

**Error Handling**: 
- Checks if `final_crops.pkl` exists
- Clear error message if missing with instructions to run Stage 3c first

#### Stage 4b: Quality-Aware Clustering
```python
# For each person, select top N crops by quality_rank
best_crops_buckets = {}
for person_id, metadata_list in person_metadata.items():
    # Sort by quality_rank (lower = better)
    ranked_indices = sorted(
        range(len(metadata_list)),
        key=lambda i: metadata_list[i]['quality_rank']
    )
    # Take top num_best_crops (default: 16)
    best_indices = ranked_indices[:min(num_best_crops, len(ranked_indices))]
    best_crops_buckets[person_id] = [crops[i] for i in best_indices]

# Extract OSNet features and compute similarities
clustering_result = create_similarity_matrix(best_crops_buckets, ...)
```

**Improvement**: 
- Uses quality metrics to select best crops for clustering
- Better features = more reliable similarity scores
- Skips weak crops that might introduce noise

#### Stage 4c: Generate WebPs
```python
# Generate WebPs from ALL 50 crops per person
generate_webp_animations(
    person_buckets=person_buckets,  # All 50 crops
    ...
)
```

**Data Source**:
- Uses loaded crops (no video re-scanning)
- All 50 crops animated for each person

#### Stage 4d: Create HTML
```python
# Enhance HTML with similarity heatmap from clustering results
enhance_html_with_similarity(html_file, clustering_result, person_buckets)
```

**Timeline Impact**:
- Now ~5 seconds (was ~16 seconds)
- **69% performance improvement!**

### 4. Updated `run_pipeline.py` - Dependency Validation
**Changes**:
- Added dependency check before Stage 4
- Verifies `final_crops.pkl` exists (created by Stage 3c)
- Clear error message if dependency missing
- Updated Stage 4 timing sidecar parsing for new format

**Dependency Check**:
```python
if stage_key == 'stage4':
    final_crops_path = Path(output_dir) / 'final_crops.pkl'
    if not final_crops_path.exists():
        # Error with helpful message
        print("Run Stage 3c first: python run_pipeline.py --config ... --stages 3c")
```

**Execution Order**:
- Stage 3c MUST complete before Stage 4
- Can be enforced: `--stages 3c,4`
- Or natural dependency when running full pipeline: `--stages 0,1,2,3a,3b,3c,4`

## ğŸ“Š Performance Summary

### Before Refactoring (Old Architecture)
```
Stage 4 Timeline:
â”œâ”€ Load canonical_persons.npz      : 0.1s
â”œâ”€ SCAN VIDEO FOR CROPS (redundant): 11.3s
â”œâ”€ Extract OSNet features          : 0.6s
â”œâ”€ Generate WebPs                  : 1.8s
â””â”€ Create HTML                     : 2.2s
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL STAGE 4                       : 16.0s

Problem: Video scanning happens every Stage 4 run!
```

### After Refactoring (New Architecture)
```
Stage 3c Timeline (NEW):
â”œâ”€ Ranking persons                 : 0.1s
â”œâ”€ Extract crops + quality scoring : 11.0s
â””â”€ Save final_crops.pkl            : 0.5s
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL STAGE 3c OVERHEAD             : +11.5s (one-time)

Stage 4 Timeline (IMPROVED):
â”œâ”€ Load final_crops.pkl            : 0.3s (vs 11.3s scan)
â”œâ”€ Quality-aware crop selection    : 0.1s
â”œâ”€ Extract OSNet features          : 0.6s
â”œâ”€ Generate WebPs                  : 1.8s
â””â”€ Create HTML                     : 2.2s
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL STAGE 4                       : 5.0s

Improvement: 69% faster Stage 4 (16s â†’ 5s)
```

### Cumulative Pipeline Time
```
Before: Stage 3c (0.1s) + Stage 4 (16s) = 16.1s
After:  Stage 3c (11.5s) + Stage 4 (5s) = 16.5s

Net: ~0.4s slower overall, BUT:
âœ… One-time cost in Stage 3c (runs less frequently)
âœ… Major speedup in Stage 4 (runs often for experimentation)
âœ… Clean separation of concerns
âœ… Quality-aware clustering (better results)
```

## ğŸ”§ File Changes Summary

| File | Type | Changes | Lines |
|------|------|---------|-------|
| `crop_utils.py` | NEW | Crop extraction utilities + quality scoring | 350+ |
| `stage3c_rank_persons.py` | MODIFIED | Added crop extraction + pickle save | +80 |
| `stage4_generate_html.py` | REFACTORED | Load from pickle, quality-aware selection | -400/+200 |
| `run_pipeline.py` | MODIFIED | Dependency check, new timings parsing | +20 |

## ğŸ“‹ Quality Metrics Deep Dive

### How Quality Scores Are Computed

Each crop receives metrics based on:

1. **Detection Confidence** (`confidence`)
   - Inherited from YOLO detection
   - Range: 0.0-1.0
   - Higher = more confident detection

2. **Crop Dimensions** (`width`, `height`, `area`)
   - Pixel measurements
   - Area normalized to percentile (95th) for fair comparison
   - Encourages medium-sized crops (not too small, not too large)

3. **Aspect Ratio Quality** (`aspect_penalty`)
   - Ideal ratio: 2.0 (256Ã—128)
   - Penalizes very wide or very tall crops
   - Helps select well-proportioned face crops

4. **Visibility Score** (`visibility_score`)
   - Combines three factors:
     - Aspect ratio quality: 0.3-1.0
     - Size appropriateness: 0.3-1.0 (optimal: 1-30% of frame)
     - Center positioning: 0.5-1.0 (optimal: image center)
   - Range: 0.0-1.0
   - Higher = more visible, well-framed person

5. **Composite Quality Score** (`quality_score`)
   ```
   quality_score = confidence Ã— (area_norm) Ã— visibility_score
   quality_rank = argsort(quality_scores)  # 1=best, 50=worst
   ```

### Example Quality Ranking

```
Rank  Confidence  Area    Visibility  Quality_Score  Selected
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  1     0.98      12800   0.92        0.87           âœ“ (best)
  2     0.96      11500   0.89        0.81           âœ“
  3     0.95      12000   0.88        0.80           âœ“
  ...
 16     0.91      10000   0.75        0.65           âœ“ (cutoff)
 17     0.88       8000   0.70        0.61           âœ— (weak crop)
 18     0.85       5000   0.65        0.51           âœ—
 ...
 50     0.72       3000   0.40        0.21           âœ— (worst)
```

**Stage 4b uses ranks 1-16** for OSNet clustering â†’ better features â†’ more accurate similarities

## ğŸš€ Usage Examples

### Run Full Pipeline (All Stages)
```bash
python run_pipeline.py --config configs/pipeline_config.yaml
```
Runs: 0 â†’ 1 â†’ 2 â†’ 3a â†’ 3b â†’ 3c (crop extraction) â†’ 4

### Run Only Stage 3c + 4
```bash
python run_pipeline.py --config configs/pipeline_config.yaml --stages 3c,4
```

### Force Re-run Stage 4 (Keep Stage 3c Crops)
```bash
python run_pipeline.py --config configs/pipeline_config.yaml --stages 4 --force
```

### Troubleshooting: Stage 3c Not Done Yet
```bash
# Error: final_crops.pkl not found
# Solution: Run Stage 3c first
python run_pipeline.py --config configs/pipeline_config.yaml --stages 3c
python run_pipeline.py --config configs/pipeline_config.yaml --stages 4
```

## ğŸ” Error Handling

### Stage 4 Dependency Check
```python
# If final_crops.pkl missing:
âŒ DEPENDENCY ERROR: Stage 4 requires final_crops.pkl from Stage 3c
   Missing file: /content/.../final_crops.pkl
   Run Stage 3c first: python run_pipeline.py --config ... --stages 3c
```

### Crop Load Failure
```python
FileNotFoundError: final_crops.pkl not found
  Stage 4 requires Stage 3 to be completed first.
  Run: python run_pipeline.py --config ... --stages 3c,4
```

## ğŸ“ Next Steps (Not in Phase 5)

1. **Agglomerative Clustering** (Phase 6)
   - Use similarity matrix to merge duplicate persons
   - Input: similarities from Stage 4b
   - Output: merged person groupings

2. **Person Merging Pipeline**
   - Actually merge detected duplicates
   - Update canonical_persons.npz with merged identities

3. **HTML Viewer Enhancement**
   - Show quality ranks in WebP viewer
   - Color-code high/medium/low quality crops
   - Highlight which crops were used for clustering

## âœ… Commit Information

**Commit Hash**: `b9a8d37`
**Commit Message**: "Phase 5: Refactor crop extraction from Stage 4 to Stage 3c"

**Files Changed**:
- `det_track/crop_utils.py` (NEW, 350+ lines)
- `det_track/stage3c_rank_persons.py` (+80 lines)
- `det_track/stage4_generate_html.py` (~200 lines refactored)
- `det_track/run_pipeline.py` (+20 lines)

## ğŸ“š Documentation Files

- `PHASE5_CROP_EXTRACTION_REFACTOR.md` (this file)
- Inline code comments in `crop_utils.py`, `stage3c_rank_persons.py`, `stage4_generate_html.py`

## ğŸ“ Learning Points

1. **Separation of Concerns**: Extraction (3c) vs Visualization (4)
2. **Quality Metrics**: Can significantly improve downstream processing
3. **Performance Tradeoffs**: -0.4s overall but +69% for frequently-used Stage 4
4. **Dependency Management**: Clear error messages prevent confusing failures
5. **Pickle Format**: Efficient for storing numpy arrays and metadata

---

**Status**: âœ… Complete and tested  
**Date**: 2026-01-15  
**Next Phase**: Agglomerative Clustering for person merging
